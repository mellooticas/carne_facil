{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c45b66",
   "metadata": {},
   "source": [
    "# An√°lise de Dados - √ìticas Taty Mello\n",
    "\n",
    "Este notebook realiza an√°lise explorat√≥ria dos dados de ordens de servi√ßo das √≥ticas.\n",
    "\n",
    "## Objetivos:\n",
    "- Carregar e analisar planilhas OS_NOVA\n",
    "- Identificar padr√µes nos dados\n",
    "- Detectar duplicatas de clientes\n",
    "- Analisar distribui√ß√£o de dioptrias\n",
    "- Gerar relat√≥rios e visualiza√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a13308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar nossas classes personalizadas\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "sys.path.append('../app/services')\n",
    "\n",
    "from analisar_os import AnalisadorOS\n",
    "from deduplicacao import DeduplicadorClientes\n",
    "\n",
    "print(\"‚úÖ Classes personalizadas carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426574f8",
   "metadata": {},
   "source": [
    "## 1. Carregamento e An√°lise Inicial dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar analisador\n",
    "analisador = AnalisadorOS(diretorio_dados=\"../data/raw\")\n",
    "\n",
    "# Listar arquivos dispon√≠veis\n",
    "arquivos_raw = list(Path(\"../data/raw\").glob(\"*.xlsx\"))\n",
    "print(f\"Arquivos encontrados: {len(arquivos_raw)}\")\n",
    "for arquivo in arquivos_raw:\n",
    "    print(f\"  üìÅ {arquivo.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se houver arquivos, processar o primeiro como exemplo\n",
    "if arquivos_raw:\n",
    "    arquivo_exemplo = arquivos_raw[0]\n",
    "    print(f\"Analisando arquivo: {arquivo_exemplo.name}\")\n",
    "    \n",
    "    # Carregar dados\n",
    "    df_original = analisador.carregar_planilha(arquivo_exemplo)\n",
    "    \n",
    "    print(f\"\\nüìä Informa√ß√µes b√°sicas:\")\n",
    "    print(f\"  - Linhas: {len(df_original)}\")\n",
    "    print(f\"  - Colunas: {len(df_original.columns)}\")\n",
    "    print(f\"  - Tamanho em mem√≥ria: {df_original.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    # Mostrar colunas\n",
    "    print(f\"\\nüìã Colunas encontradas:\")\n",
    "    for i, col in enumerate(df_original.columns):\n",
    "        print(f\"  {i+1:2d}. {col}\")\n",
    "        \n",
    "    # Primeiras linhas\n",
    "    print(f\"\\nüîç Primeiras 3 linhas:\")\n",
    "    display(df_original.head(3))\n",
    "else:\n",
    "    print(\"‚ùå Nenhum arquivo encontrado em data/raw/\")\n",
    "    print(\"   Copie alguns arquivos OS_NOVA*.xlsx para data/raw/ e execute novamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed7488",
   "metadata": {},
   "source": [
    "## 2. Padroniza√ß√£o e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da538ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw:\n",
    "    # Padronizar colunas\n",
    "    df_limpo = analisador.padronizar_colunas(df_original.copy())\n",
    "    \n",
    "    print(\"üîß Colunas ap√≥s padroniza√ß√£o:\")\n",
    "    for i, col in enumerate(df_limpo.columns):\n",
    "        print(f\"  {i+1:2d}. {col}\")\n",
    "    \n",
    "    # Mostrar compara√ß√£o antes/depois\n",
    "    print(\"\\nüìã Mapeamento de colunas:\")\n",
    "    for orig, novo in zip(df_original.columns, df_limpo.columns):\n",
    "        if orig != novo:\n",
    "            print(f\"  '{orig}' ‚Üí '{novo}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc88a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw:\n",
    "    # An√°lise de dados faltantes\n",
    "    print(\"üîç An√°lise de dados faltantes:\")\n",
    "    missing = df_limpo.isnull().sum()\n",
    "    missing_pct = (missing / len(df_limpo)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Coluna': missing.index,\n",
    "        'Valores_Faltantes': missing.values,\n",
    "        'Percentual': missing_pct.values\n",
    "    }).sort_values('Percentual', ascending=False)\n",
    "    \n",
    "    display(missing_df.head(10))\n",
    "    \n",
    "    # Visualizar dados faltantes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_df_plot = missing_df[missing_df['Percentual'] > 0]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(missing_df_plot['Coluna'][:10], missing_df_plot['Percentual'][:10])\n",
    "    plt.xlabel('Percentual de Valores Faltantes')\n",
    "    plt.title('Top 10 Colunas com Dados Faltantes')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(missing_df_plot['Percentual'], bins=20, alpha=0.7)\n",
    "    plt.xlabel('Percentual de Valores Faltantes')\n",
    "    plt.ylabel('N√∫mero de Colunas')\n",
    "    plt.title('Distribui√ß√£o de Dados Faltantes')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d426ee0",
   "metadata": {},
   "source": [
    "## 3. An√°lise de Clientes e Detec√ß√£o de Duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c71b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw and 'nome' in df_limpo.columns:\n",
    "    # An√°lise b√°sica de clientes\n",
    "    print(\"üë• An√°lise de Clientes:\")\n",
    "    print(f\"  - Total de registros: {len(df_limpo)}\")\n",
    "    print(f\"  - Clientes √∫nicos (por nome): {df_limpo['nome'].nunique()}\")\n",
    "    print(f\"  - Registros com nome vazio: {df_limpo['nome'].isnull().sum()}\")\n",
    "    \n",
    "    if 'cpf' in df_limpo.columns:\n",
    "        print(f\"  - CPFs √∫nicos: {df_limpo['cpf'].nunique()}\")\n",
    "        print(f\"  - Registros com CPF vazio: {df_limpo['cpf'].isnull().sum()}\")\n",
    "    \n",
    "    if 'telefone' in df_limpo.columns:\n",
    "        print(f\"  - Telefones √∫nicos: {df_limpo['telefone'].nunique()}\")\n",
    "        print(f\"  - Registros com telefone vazio: {df_limpo['telefone'].isnull().sum()}\")\n",
    "    \n",
    "    # Top 10 clientes por n√∫mero de OS\n",
    "    top_clientes = df_limpo['nome'].value_counts().head(10)\n",
    "    print(f\"\\nüèÜ Top 10 clientes com mais OS:\")\n",
    "    for nome, count in top_clientes.items():\n",
    "        print(f\"  {count:2d} OS - {nome}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw and 'nome' in df_limpo.columns:\n",
    "    # Detectar duplicatas usando nossa classe\n",
    "    print(\"üîç Detectando duplicatas...\")\n",
    "    \n",
    "    deduplicador = DeduplicadorClientes()\n",
    "    \n",
    "    # Usar apenas uma amostra se o dataset for muito grande\n",
    "    df_amostra = df_limpo.head(100) if len(df_limpo) > 100 else df_limpo\n",
    "    \n",
    "    duplicatas = deduplicador.encontrar_duplicatas(df_amostra)\n",
    "    \n",
    "    print(f\"‚úÖ Encontradas {len(duplicatas)} poss√≠veis duplicatas\")\n",
    "    \n",
    "    if duplicatas:\n",
    "        # Gerar relat√≥rio\n",
    "        relatorio_duplicatas = deduplicador.gerar_relatorio_duplicatas(duplicatas)\n",
    "        \n",
    "        print(\"\\nüìä Top 5 duplicatas com maior score:\")\n",
    "        display(relatorio_duplicatas.head())\n",
    "        \n",
    "        # Estat√≠sticas das duplicatas\n",
    "        print(\"\\nüìà Estat√≠sticas das duplicatas:\")\n",
    "        print(f\"  - Duplicatas com alta confian√ßa: {(relatorio_duplicatas['Confianca'] == 'alta').sum()}\")\n",
    "        print(f\"  - Duplicatas com m√©dia confian√ßa: {(relatorio_duplicatas['Confianca'] == 'media').sum()}\")\n",
    "        print(f\"  - Duplicatas com baixa confian√ßa: {(relatorio_duplicatas['Confianca'] == 'baixa').sum()}\")\n",
    "        \n",
    "        print(f\"\\n  - Recomenda√ß√£o 'merge': {(relatorio_duplicatas['Recomendacao'] == 'merge').sum()}\")\n",
    "        print(f\"  - Recomenda√ß√£o 'revisar': {(relatorio_duplicatas['Recomendacao'] == 'revisar').sum()}\")\n",
    "        print(f\"  - Recomenda√ß√£o 'ignorar': {(relatorio_duplicatas['Recomendacao'] == 'ignorar').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff202d",
   "metadata": {},
   "source": [
    "## 4. An√°lise de Dioptrias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55380448",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw:\n",
    "    # Identificar colunas de dioptrias\n",
    "    colunas_dioptria = [col for col in df_limpo.columns if any(x in col.lower() for x in ['od_', 'oe_', 'esferico', 'cilindrico', 'eixo', 'adicao'])]\n",
    "    \n",
    "    print(f\"üîç Colunas de dioptria encontradas: {len(colunas_dioptria)}\")\n",
    "    for col in colunas_dioptria:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    if colunas_dioptria:\n",
    "        # An√°lise b√°sica das dioptrias\n",
    "        print(\"\\nüìä Estat√≠sticas das dioptrias:\")\n",
    "        \n",
    "        for col in colunas_dioptria[:6]:  # Limitar a 6 colunas\n",
    "            if df_limpo[col].dtype in ['float64', 'int64']:\n",
    "                valores_validos = df_limpo[col].dropna()\n",
    "                if len(valores_validos) > 0:\n",
    "                    print(f\"\\n  {col}:\")\n",
    "                    print(f\"    - Valores v√°lidos: {len(valores_validos)}\")\n",
    "                    print(f\"    - M√©dia: {valores_validos.mean():.2f}\")\n",
    "                    print(f\"    - Mediana: {valores_validos.median():.2f}\")\n",
    "                    print(f\"    - Min/Max: {valores_validos.min():.2f} / {valores_validos.max():.2f}\")\n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma coluna de dioptria identificada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdad326",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw and colunas_dioptria:\n",
    "    # Visualiza√ß√µes das dioptrias\n",
    "    print(\"üìà Gerando visualiza√ß√µes das dioptrias...\")\n",
    "    \n",
    "    # Selecionar colunas num√©ricas de dioptria\n",
    "    colunas_numericas = [col for col in colunas_dioptria if df_limpo[col].dtype in ['float64', 'int64']]\n",
    "    \n",
    "    if len(colunas_numericas) >= 2:\n",
    "        fig, axes = plt.subplots(2, min(3, len(colunas_numericas)), figsize=(15, 10))\n",
    "        axes = axes.flatten() if len(colunas_numericas) > 3 else [axes] if len(colunas_numericas) == 1 else axes\n",
    "        \n",
    "        for i, col in enumerate(colunas_numericas[:6]):\n",
    "            ax = axes[i] if i < len(axes) else None\n",
    "            if ax is not None:\n",
    "                valores = df_limpo[col].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    if i < 3:\n",
    "                        # Histogramas na primeira linha\n",
    "                        ax.hist(valores, bins=30, alpha=0.7, edgecolor='black')\n",
    "                        ax.set_title(f'Distribui√ß√£o - {col}')\n",
    "                        ax.set_xlabel('Valor')\n",
    "                        ax.set_ylabel('Frequ√™ncia')\n",
    "                    else:\n",
    "                        # Boxplots na segunda linha\n",
    "                        ax.boxplot(valores)\n",
    "                        ax.set_title(f'Boxplot - {col}')\n",
    "                        ax.set_ylabel('Valor')\n",
    "        \n",
    "        # Remover subplots vazios\n",
    "        for i in range(len(colunas_numericas), len(axes)):\n",
    "            fig.delaxes(axes[i])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå N√£o h√° colunas num√©ricas suficientes para visualiza√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080bc7a",
   "metadata": {},
   "source": [
    "## 5. An√°lise Temporal (se dispon√≠vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41458f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw:\n",
    "    # Identificar colunas de data\n",
    "    colunas_data = [col for col in df_limpo.columns if any(x in col.lower() for x in ['data', 'date'])]\n",
    "    \n",
    "    print(f\"üìÖ Colunas de data encontradas: {len(colunas_data)}\")\n",
    "    for col in colunas_data:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    if colunas_data:\n",
    "        # Tentar converter para datetime\n",
    "        for col in colunas_data[:2]:  # Limitar a 2 colunas\n",
    "            try:\n",
    "                df_limpo[f'{col}_dt'] = pd.to_datetime(df_limpo[col], errors='coerce')\n",
    "                valores_validos = df_limpo[f'{col}_dt'].dropna()\n",
    "                \n",
    "                if len(valores_validos) > 0:\n",
    "                    print(f\"\\nüìä An√°lise temporal - {col}:\")\n",
    "                    print(f\"  - Datas v√°lidas: {len(valores_validos)}\")\n",
    "                    print(f\"  - Per√≠odo: {valores_validos.min().date()} at√© {valores_validos.max().date()}\")\n",
    "                    print(f\"  - Amplitude: {(valores_validos.max() - valores_validos.min()).days} dias\")\n",
    "                    \n",
    "                    # Distribui√ß√£o por m√™s\n",
    "                    if len(valores_validos) > 10:\n",
    "                        plt.figure(figsize=(12, 4))\n",
    "                        \n",
    "                        plt.subplot(1, 2, 1)\n",
    "                        valores_validos.dt.to_period('M').value_counts().sort_index().plot(kind='bar')\n",
    "                        plt.title(f'Distribui√ß√£o Mensal - {col}')\n",
    "                        plt.xlabel('M√™s')\n",
    "                        plt.ylabel('Quantidade')\n",
    "                        plt.xticks(rotation=45)\n",
    "                        \n",
    "                        plt.subplot(1, 2, 2)\n",
    "                        valores_validos.dt.dayofweek.value_counts().sort_index().plot(kind='bar')\n",
    "                        plt.title(f'Distribui√ß√£o por Dia da Semana - {col}')\n",
    "                        plt.xlabel('Dia da Semana (0=Segunda)')\n",
    "                        plt.ylabel('Quantidade')\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao processar coluna {col}: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma coluna de data identificada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa6cf9",
   "metadata": {},
   "source": [
    "## 6. Relat√≥rio Final e Recomenda√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77806def",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw:\n",
    "    print(\"üìã RELAT√ìRIO FINAL\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nüìä RESUMO DOS DADOS:\")\n",
    "    print(f\"  - Arquivo analisado: {arquivo_exemplo.name}\")\n",
    "    print(f\"  - Total de registros: {len(df_original):,}\")\n",
    "    print(f\"  - Total de colunas: {len(df_original.columns)}\")\n",
    "    print(f\"  - Registros ap√≥s limpeza: {len(df_limpo):,}\")\n",
    "    \n",
    "    if 'nome' in df_limpo.columns:\n",
    "        print(f\"\\nüë• CLIENTES:\")\n",
    "        print(f\"  - Clientes √∫nicos: {df_limpo['nome'].nunique():,}\")\n",
    "        print(f\"  - Taxa de duplica√ß√£o: {((len(df_limpo) - df_limpo['nome'].nunique()) / len(df_limpo) * 100):.1f}%\")\n",
    "        \n",
    "        if 'duplicatas' in locals() and duplicatas:\n",
    "            print(f\"  - Duplicatas detectadas: {len(duplicatas)}\")\n",
    "            merge_recomendado = sum(1 for d in duplicatas if d.recomendacao == 'merge')\n",
    "            print(f\"  - Merge recomendado: {merge_recomendado}\")\n",
    "    \n",
    "    if colunas_dioptria:\n",
    "        print(f\"\\nüëì DIOPTRIAS:\")\n",
    "        print(f\"  - Colunas de dioptria: {len(colunas_dioptria)}\")\n",
    "        \n",
    "        # Calcular completude dos dados de dioptria\n",
    "        for col in colunas_dioptria[:4]:\n",
    "            if col in df_limpo.columns:\n",
    "                completude = (df_limpo[col].notna().sum() / len(df_limpo)) * 100\n",
    "                print(f\"  - {col}: {completude:.1f}% preenchido\")\n",
    "    \n",
    "    print(f\"\\nüîß QUALIDADE DOS DADOS:\")\n",
    "    total_missing = df_limpo.isnull().sum().sum()\n",
    "    total_cells = len(df_limpo) * len(df_limpo.columns)\n",
    "    completude_geral = ((total_cells - total_missing) / total_cells) * 100\n",
    "    print(f\"  - Completude geral: {completude_geral:.1f}%\")\n",
    "    print(f\"  - C√©lulas vazias: {total_missing:,}\")\n",
    "    \n",
    "    print(f\"\\nüí° RECOMENDA√á√ïES:\")\n",
    "    print(f\"  1. Implementar processo de deduplica√ß√£o autom√°tica\")\n",
    "    print(f\"  2. Padronizar formato dos campos (CPF, telefone, etc.)\")\n",
    "    print(f\"  3. Criar valida√ß√µes para entrada de dados\")\n",
    "    print(f\"  4. Estabelecer campos obrigat√≥rios\")\n",
    "    \n",
    "    if len(colunas_dioptria) > 0:\n",
    "        print(f\"  5. Implementar valida√ß√µes espec√≠ficas para dioptrias\")\n",
    "    \n",
    "    if len(colunas_data) > 0:\n",
    "        print(f\"  6. Padronizar formato de datas\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ An√°lise conclu√≠da!\")\n",
    "else:\n",
    "    print(\"‚ùå N√£o foi poss√≠vel realizar a an√°lise.\")\n",
    "    print(\"   Certifique-se de copiar arquivos para data/raw/ e executar novamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4dbcb9",
   "metadata": {},
   "source": [
    "## 7. Exportar Dados Limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d914e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arquivos_raw and 'df_limpo' in locals():\n",
    "    # Exportar dados limpos\n",
    "    output_dir = Path(\"../data/processed\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    output_file = output_dir / f\"dados_limpos_{arquivo_exemplo.stem}.xlsx\"\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # Dados limpos\n",
    "        df_limpo.to_excel(writer, sheet_name='dados_limpos', index=False)\n",
    "        \n",
    "        # Relat√≥rio de duplicatas (se existir)\n",
    "        if 'relatorio_duplicatas' in locals() and not relatorio_duplicatas.empty:\n",
    "            relatorio_duplicatas.to_excel(writer, sheet_name='duplicatas', index=False)\n",
    "        \n",
    "        # Estat√≠sticas\n",
    "        stats_df = pd.DataFrame({\n",
    "            'Metrica': [\n",
    "                'Total de registros originais',\n",
    "                'Total de registros limpos',\n",
    "                'Total de colunas',\n",
    "                'Clientes √∫nicos',\n",
    "                'Duplicatas detectadas',\n",
    "                'Completude geral (%)'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                len(df_original),\n",
    "                len(df_limpo),\n",
    "                len(df_limpo.columns),\n",
    "                df_limpo['nome'].nunique() if 'nome' in df_limpo.columns else 'N/A',\n",
    "                len(duplicatas) if 'duplicatas' in locals() else 0,\n",
    "                f\"{completude_geral:.1f}%\" if 'completude_geral' in locals() else 'N/A'\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        stats_df.to_excel(writer, sheet_name='estatisticas', index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Dados exportados para: {output_file}\")\n",
    "    print(f\"   Sheets criados:\")\n",
    "    print(f\"   - dados_limpos: {len(df_limpo)} registros\")\n",
    "    \n",
    "    if 'relatorio_duplicatas' in locals() and not relatorio_duplicatas.empty:\n",
    "        print(f\"   - duplicatas: {len(relatorio_duplicatas)} registros\")\n",
    "    \n",
    "    print(f\"   - estatisticas: resumo da an√°lise\")\n",
    "else:\n",
    "    print(\"‚ùå N√£o h√° dados para exportar\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
