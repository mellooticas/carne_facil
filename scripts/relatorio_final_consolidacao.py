#!/usr/bin/env python3
"""
RelatÃ³rio Detalhado dos Resultados da ConsolidaÃ§Ã£o Por Loja
"""

import pandas as pd
from pathlib import Path
from datetime import datetime

def gerar_relatorio_completo():
    """Gera relatÃ³rio completo com anÃ¡lises e visualizaÃ§Ãµes"""
    
    print("ğŸ“Š RELATÃ“RIO DETALHADO - CONSOLIDAÃ‡ÃƒO POR LOJA")
    print("=" * 80)
    print(f"ğŸ“… Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print("=" * 80)
    
    # Carregar dados
    dashboard_file = Path("data/processed/dashboard_consolidacao_por_loja.xlsx")
    
    if not dashboard_file.exists():
        print("âŒ Dashboard nÃ£o encontrado. Execute primeiro a consolidaÃ§Ã£o!")
        return
    
    try:
        # Carregar todas as sheets
        excel_file = pd.ExcelFile(dashboard_file)
        df_dashboard = pd.read_excel(dashboard_file, sheet_name='Dashboard_Principal')
        df_resumo_loja = pd.read_excel(dashboard_file, sheet_name='Resumo_Por_Loja')
        df_stats = pd.read_excel(dashboard_file, sheet_name='Estatisticas_Gerais')
        
        # Carregar qualidade se existir
        df_qualidade = None
        try:
            df_qualidade = pd.read_excel(dashboard_file, sheet_name='Qualidade_Dados')
        except:
            pass
        
        print("\nğŸ” ANÃLISE GERAL:")
        print("-" * 50)
        
        # EstatÃ­sticas principais
        sucessos = df_dashboard[df_dashboard['status'] == 'sucesso']
        erros = df_dashboard[df_dashboard['status'] == 'erro']
        
        print(f"ğŸ“ Total de arquivos analisados: {len(df_dashboard)}")
        print(f"âœ… Processados com sucesso: {len(sucessos)} ({len(sucessos)/len(df_dashboard)*100:.1f}%)")
        print(f"âŒ Erros encontrados: {len(erros)} ({len(erros)/len(df_dashboard)*100:.1f}%)")
        
        if len(sucessos) > 0:
            total_originais = sucessos['registros_originais'].sum()
            total_consolidados = sucessos['registros_consolidados'].sum()
            total_duplicatas = sucessos['duplicatas_encontradas'].sum()
            total_os = sucessos['total_os'].sum()
            
            print(f"\nğŸ“Š NÃšMEROS CONSOLIDADOS:")
            print(f"   ğŸ“‹ Registros originais: {total_originais:,}")
            print(f"   ğŸ“‹ Registros consolidados: {total_consolidados:,}")
            print(f"   ğŸ”„ Duplicatas removidas: {total_duplicatas:,}")
            print(f"   ğŸ“ˆ Taxa de duplicaÃ§Ã£o: {(total_duplicatas/total_originais*100):.1f}%")
            print(f"   ğŸ¯ EficiÃªncia da consolidaÃ§Ã£o: {((total_originais-total_consolidados)/total_originais*100):.1f}%")
            print(f"   ğŸ“ Total de OS identificadas: {total_os:,}")
        
        print(f"\nğŸª ANÃLISE POR LOJA:")
        print("-" * 50)
        
        # AnÃ¡lise por loja
        df_resumo_sorted = df_resumo_loja.sort_values('registros_originais', ascending=False)
        
        for _, loja in df_resumo_sorted.iterrows():
            reducao = ((loja['registros_originais'] - loja['registros_consolidados']) / loja['registros_originais'] * 100) if loja['registros_originais'] > 0 else 0
            
            print(f"\nğŸ¢ {loja['loja']}:")
            print(f"   ğŸ“ Arquivos: {loja['total_arquivos']}")
            print(f"   ğŸ“Š {loja['registros_originais']:,} â†’ {loja['registros_consolidados']:,} registros")
            print(f"   ğŸ”„ {loja['duplicatas_encontradas']:,} duplicatas ({reducao:.1f}% reduÃ§Ã£o)")
            print(f"   ğŸ“ {loja['total_os']:,} OS identificadas")
        
        print(f"\nğŸ“ˆ TOP 10 ARQUIVOS COM MAIS DUPLICATAS:")
        print("-" * 50)
        
        # Top arquivos com duplicatas
        top_duplicatas = sucessos.nlargest(10, 'duplicatas_encontradas')
        
        for i, (_, arquivo) in enumerate(top_duplicatas.iterrows(), 1):
            reducao = ((arquivo['registros_originais'] - arquivo['registros_consolidados']) / arquivo['registros_originais'] * 100) if arquivo['registros_originais'] > 0 else 0
            nome_arquivo = arquivo['arquivo'][:40] + "..." if len(arquivo['arquivo']) > 40 else arquivo['arquivo']
            
            print(f"{i:2d}. {nome_arquivo}")
            print(f"    ğŸª {arquivo['loja']} | ğŸ“Š {arquivo['registros_originais']} â†’ {arquivo['registros_consolidados']} | ğŸ”„ {arquivo['duplicatas_encontradas']} duplicatas ({reducao:.1f}%)")
        
        if df_qualidade is not None:
            print(f"\nğŸ“‹ QUALIDADE DOS DADOS:")
            print("-" * 50)
            
            # AnÃ¡lise de qualidade por campo
            qualidade_por_campo = df_qualidade.groupby('campo').agg({
                'preenchidos': 'sum',
                'total': 'sum'
            }).reset_index()
            
            qualidade_por_campo['percentual'] = (qualidade_por_campo['preenchidos'] / qualidade_por_campo['total'] * 100)
            qualidade_por_campo = qualidade_por_campo.sort_values('percentual', ascending=False)
            
            for _, campo in qualidade_por_campo.iterrows():
                status = "ğŸŸ¢" if campo['percentual'] >= 80 else "ğŸŸ¡" if campo['percentual'] >= 50 else "ğŸ”´"
                campo_nome = "CELULAR" if campo['campo'] == 'celular' else campo['campo'].upper()
                print(f"{status} {campo_nome}: {campo['percentual']:.1f}% ({campo['preenchidos']:,}/{campo['total']:,})")
        
        print(f"\nğŸ¯ ESTRATÃ‰GIA APLICADA:")
        print("-" * 50)
        print("âœ… ConsolidaÃ§Ã£o POR ARQUIVO/LOJA (nÃ£o entre lojas)")
        print("âœ… CritÃ©rios seguros: CPF exato OU Nome + Data Nascimento")
        print("âœ… PreservaÃ§Ã£o da integridade das lojas")
        print("âœ… Mesclagem inteligente de informaÃ§Ãµes")
        
        print(f"\nğŸ“ ARQUIVOS GERADOS:")
        print("-" * 50)
        print(f"ğŸ“Š Dashboard principal: {dashboard_file}")
        
        # Listar arquivos consolidados por loja
        output_dir = Path("data/processed/por_arquivo")
        if output_dir.exists():
            arquivos_individuais = list(output_dir.glob("*_consolidado.xlsx"))
            print(f"ğŸ“ Arquivos individuais: {len(arquivos_individuais)} em {output_dir}")
        
        print(f"\nğŸš€ PRÃ“XIMAS ETAPAS SUGERIDAS:")
        print("-" * 50)
        print("1. ğŸ“‹ Normalizar sequÃªncias de OS por loja")
        print("2. ğŸ” AnÃ¡lise detalhada de clientes com mÃºltiplas OS")
        print("3. ğŸ“Š Implementar dashboard de vendas por loja")
        print("4. ğŸª Configurar sistema de entrada contÃ­nua de dados")
        print("5. ğŸ“ˆ AnÃ¡lises de tendÃªncias e relatÃ³rios gerenciais")
        
        print(f"\nğŸ’¡ INSIGHTS IDENTIFICADOS:")
        print("-" * 50)
        
        if len(sucessos) > 0:
            # Insights automÃ¡ticos
            loja_mais_duplicatas = df_resumo_sorted.iloc[0]
            arquivo_mais_problematico = sucessos.loc[sucessos['duplicatas_encontradas'].idxmax()]
            
            print(f"ğŸ“Š Loja com mais duplicatas: {loja_mais_duplicatas['loja']} ({loja_mais_duplicatas['duplicatas_encontradas']:,} duplicatas)")
            print(f"ğŸ“ Arquivo mais problemÃ¡tico: {arquivo_mais_problematico['arquivo'][:50]}...")
            print(f"ğŸ¯ Taxa mÃ©dia de duplicaÃ§Ã£o: {(sucessos['duplicatas_encontradas'].sum()/sucessos['registros_originais'].sum()*100):.1f}%")
            
            # DistribuiÃ§Ã£o de arquivos por loja
            dist_lojas = sucessos['loja'].value_counts()
            print(f"ğŸª DistribuiÃ§Ã£o: {', '.join([f'{loja}({count})' for loja, count in dist_lojas.head(3).items()])}")
        
        print(f"\nğŸŒ DASHBOARD WEB:")
        print("-" * 50)
        print("ğŸš€ Acesse: http://localhost:8001")
        print("ğŸ“Š Dashboard interativo com filtros por loja")
        print("ğŸ“ˆ MÃ©tricas em tempo real e visualizaÃ§Ãµes")
        
        print("\n" + "=" * 80)
        print("ğŸ‰ RELATÃ“RIO CONCLUÃDO COM SUCESSO!")
        print("=" * 80)
        
    except Exception as e:
        print(f"âŒ Erro ao gerar relatÃ³rio: {e}")

def main():
    """FunÃ§Ã£o principal"""
    gerar_relatorio_completo()

if __name__ == "__main__":
    main()