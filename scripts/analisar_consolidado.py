#!/usr/bin/env python3
"""
An√°lise dos dados consolidados das lojas operacionais
"""

import pandas as pd
import numpy as np
from pathlib import Path

def analisar_dados_consolidados():
    """Analisa o arquivo consolidado das lojas operacionais"""
    
    print("üîç AN√ÅLISE DOS DADOS CONSOLIDADOS")
    print("="*60)
    
    # Caminho do arquivo consolidado
    arquivo_consolidado = Path("data/processed/lojas_operacionais_consolidado.xlsx")
    
    if not arquivo_consolidado.exists():
        print("‚ùå Arquivo consolidado n√£o encontrado!")
        return
    
    # Carregar dados
    print("üìÇ Carregando dados consolidados...")
    df = pd.read_excel(arquivo_consolidado)
    
    print(f"üìä Total de registros: {len(df):,}")
    print(f"üìä Total de colunas: {len(df.columns)}")
    print()
    
    # Estrutura dos dados
    print("üìã ESTRUTURA DOS DADOS")
    print("-" * 40)
    print("üè∑Ô∏è Colunas dispon√≠veis:")
    for i, col in enumerate(df.columns, 1):
        print(f"   {i:2d}. {col}")
    print()
    
    # Primeiras linhas
    print("üëÄ PRIMEIRAS 10 LINHAS")
    print("-" * 40)
    print(df.head(10).to_string())
    print()
    
    # Estat√≠sticas por loja
    if 'loja' in df.columns:
        print("üìä ESTAT√çSTICAS POR LOJA")
        print("-" * 40)
        
        stats_loja = df.groupby('loja').agg({
            'loja': 'count',  # Total de registros
        }).rename(columns={'loja': 'total_registros'})
        
        # Verificar se h√° colunas de OS
        for col in ['OS_LANCASTER', 'OS_OTM', 'os_lancaster', 'os_otm']:
            if col in df.columns:
                stats_loja[f'{col}_validas'] = df.groupby('loja')[col].count()
                stats_loja[f'{col}_min'] = df.groupby('loja')[col].min()
                stats_loja[f'{col}_max'] = df.groupby('loja')[col].max()
        
        print(stats_loja)
        print()
    
    # Verificar duplica√ß√µes
    print("üîç AN√ÅLISE DE DUPLICA√á√ïES")
    print("-" * 40)
    
    # Duplica√ß√µes por OS LANCASTER
    for col in ['OS_LANCASTER', 'os_lancaster']:
        if col in df.columns:
            duplicados = df[df[col].duplicated(keep=False)]
            if not duplicados.empty:
                print(f"‚ö†Ô∏è {col}: {len(duplicados)} registros duplicados")
                print("   Exemplos de duplica√ß√µes:")
                exemplos = duplicados.groupby(col)['loja'].apply(list).head(5)
                for os_num, lojas in exemplos.items():
                    print(f"     OS {os_num}: {', '.join(lojas)}")
            else:
                print(f"‚úÖ {col}: Sem duplica√ß√µes")
    
    # Duplica√ß√µes por OS OTM
    for col in ['OS_OTM', 'os_otm']:
        if col in df.columns:
            duplicados = df[df[col].duplicated(keep=False)]
            if not duplicados.empty:
                print(f"‚ö†Ô∏è {col}: {len(duplicados)} registros duplicados")
                print("   Exemplos de duplica√ß√µes:")
                exemplos = duplicados.groupby(col)['loja'].apply(list).head(5)
                for os_num, lojas in exemplos.items():
                    print(f"     OS {os_num}: {', '.join(lojas)}")
            else:
                print(f"‚úÖ {col}: Sem duplica√ß√µes")
    
    print()
    
    # Valores √∫nicos em colunas categ√≥ricas
    print("üìä VALORES √öNICOS")
    print("-" * 40)
    
    for col in df.columns:
        if df[col].dtype == 'object' or df[col].nunique() <= 20:
            valores_unicos = df[col].value_counts()
            print(f"üè∑Ô∏è {col}:")
            print(f"   Total de valores √∫nicos: {df[col].nunique()}")
            if df[col].nunique() <= 10:
                print("   Valores:")
                for valor, count in valores_unicos.items():
                    print(f"     ‚Ä¢ {valor}: {count}")
            else:
                print("   Top 5 valores:")
                for valor, count in valores_unicos.head().items():
                    print(f"     ‚Ä¢ {valor}: {count}")
            print()
    
    # Verificar dados nulos
    print("üîç DADOS NULOS")
    print("-" * 40)
    nulos = df.isnull().sum()
    nulos_perc = (nulos / len(df) * 100).round(2)
    
    for col in df.columns:
        if nulos[col] > 0:
            print(f"‚ö†Ô∏è {col}: {nulos[col]} nulos ({nulos_perc[col]}%)")
        else:
            print(f"‚úÖ {col}: Sem dados nulos")
    
    print("\nüéâ An√°lise conclu√≠da!")

if __name__ == "__main__":
    analisar_dados_consolidados()